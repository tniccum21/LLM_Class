{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG System with LM Studio\n",
    "\n",
    "A lightweight Retrieval-Augmented Generation (RAG) system using:\n",
    "- **LM Studio** for local LLM inference\n",
    "- **ChromaDB** for local vector storage\n",
    "- **Sentence Transformers** for embeddings\n",
    "\n",
    "## Prerequisites\n",
    "1. Install and run LM Studio with a model loaded (e.g., Mistral, Llama)\n",
    "2. Ensure LM Studio server is running (default: http://localhost:1234)\n",
    "3. Place your PDF file in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Architecture\n",
    "\n",
    "### Components:\n",
    "\n",
    "1. **PDF Processing**\n",
    "   - PyPDF2 for text extraction\n",
    "   - Custom chunking with overlap\n",
    "\n",
    "2. **Embeddings**\n",
    "   - Sentence Transformers (all-MiniLM-L6-v2)\n",
    "   - Local, fast, no API calls\n",
    "\n",
    "3. **Vector Storage**\n",
    "   - ChromaDB (embedded database)\n",
    "   - Persistent local storage\n",
    "   - Cosine similarity search\n",
    "\n",
    "4. **LLM Integration**\n",
    "   - LM Studio (OpenAI-compatible API)\n",
    "   - Local inference, no cloud dependency\n",
    "\n",
    "### Data Flow:\n",
    "```\n",
    "PDF → Extract Text → Chunk → Embed → Store in ChromaDB\n",
    "                                           ↓\n",
    "User Question → Embed → Search ChromaDB → Retrieve Chunks\n",
    "                                           ↓\n",
    "                         Context + Question → LM Studio → Answer\n",
    "```\n",
    "\n",
    "### Configuration Tips:\n",
    "\n",
    "- **Chunk Size**: 500 chars works well for most documents\n",
    "- **Overlap**: 50 chars prevents losing context at boundaries\n",
    "- **Top K**: 3 chunks usually provides enough context\n",
    "- **Temperature**: 0.7 for balanced creativity/accuracy\n",
    "\n",
    "### Performance:\n",
    "\n",
    "- Embedding generation: ~1 second per 100 chunks\n",
    "- Vector search: <100ms\n",
    "- LLM response: Depends on model and hardware\n",
    "\n",
    "### Troubleshooting:\n",
    "\n",
    "1. **LM Studio not connecting**: Check server is running on port 1234\n",
    "2. **Poor quality answers**: Try adjusting chunk_size or top_k\n",
    "3. **Slow performance**: Use smaller embedding model or reduce chunk count\n",
    "4. **Out of memory**: Process PDFs in batches or use smaller chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: sentence-transformers in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (5.1.1)\n",
      "Requirement already satisfied: PyPDF2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: requests in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: numpy in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: IProgress in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (0.4)\n",
      "Requirement already satisfied: ipywidgets in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (8.1.7)\n",
      "Requirement already satisfied: build>=1.0.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (0.19.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sentence-transformers) (4.56.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sentence-transformers) (0.35.1)\n",
      "Requirement already satisfied: Pillow in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: pyproject_hooks in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: decorator in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: networkx in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Volumes/RAID0/repos/Apps_with_AI/.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install chromadb sentence-transformers PyPDF2 requests numpy IProgress ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import PyPDF2\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configuration\n",
    "LM_STUDIO_URL = \"http://127.0.0.1:1234\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  # Small, fast, good quality\n",
    "CHUNK_SIZE = 500  # Characters per chunk\n",
    "CHUNK_OVERLAP = 50  # Overlap between chunks\n",
    "TOP_K = 5  # Number of relevant chunks to retrieve\n",
    "TEMPERATURE = 0.2\n",
    "LLM_MODEL = \"openai/gpt-oss-20b\"\n",
    "# Specify your PDF file path\n",
    "PDF_PATH = \"1706.03762v7.pdf\"  # <-- Change this to your PDF file name\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load from your specific file name\n",
    "load_dotenv('secrets.env', override=True)\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "print(f\"Token loaded.\")\n",
    "\n",
    "login(token=token)\n",
    "print(\"Login successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "✅ Loaded all-MiniLM-L6-v2\n",
      "\n",
      "Initializing ChromaDB...\n",
      "✅ Using existing collection: pdf_documents\n",
      "\n",
      "✅ LM Studio is connected and ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "embedder = SentenceTransformer(EMBEDDING_MODEL)\n",
    "print(f\"✅ Loaded {EMBEDDING_MODEL}\")\n",
    "\n",
    "# Initialize ChromaDB (persistent local storage)\n",
    "print(\"\\nInitializing ChromaDB...\")\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Create or get collection\n",
    "collection_name = \"pdf_documents\"\n",
    "try:\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    print(f\"✅ Created new collection: {collection_name}\")\n",
    "except:\n",
    "    collection = chroma_client.get_collection(name=collection_name)\n",
    "    print(f\"✅ Using existing collection: {collection_name}\")\n",
    "\n",
    "# Test LM Studio connection\n",
    "\n",
    "\n",
    "# Initialize OpenAI client for LM Studio\n",
    "client = OpenAI(\n",
    "    base_url=f\"{LM_STUDIO_URL}/v1\",\n",
    "    api_key=\"lm-studio\"  # LM Studio doesn't need real API key\n",
    ")\n",
    "\n",
    "# Test LM Studio connection\n",
    "def test_lm_studio():\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Say 'connected'\"}],\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=10,\n",
    "            timeout=30\n",
    "        )\n",
    "        print(\"\\n✅ LM Studio is connected and ready\")\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    print(\"\\n⚠️ LM Studio not responding. Please ensure:\")\n",
    "    print(\"1. LM Studio is running\")\n",
    "    print(\"2. A model is loaded\")\n",
    "    print(\"3. Server is started (default port 1234)\")\n",
    "    return False\n",
    "\n",
    "test_lm_studio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Document processing functions ready\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from PDF file\"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            print(f\"📄 Processing {num_pages} pages...\")\n",
    "            \n",
    "            for page_num in range(num_pages):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "                \n",
    "        print(f\"✅ Extracted {len(text)} characters from PDF\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def create_chunks(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
    "    \"\"\"Split text into overlapping chunks\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        \n",
    "        # Clean up chunk\n",
    "        chunk = chunk.strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        start += chunk_size - overlap\n",
    "    \n",
    "    print(f\"✅ Created {len(chunks)} chunks\")\n",
    "    return chunks\n",
    "\n",
    "def embed_chunks(chunks: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings for text chunks\"\"\"\n",
    "    print(\"🔄 Generating embeddings...\")\n",
    "    embeddings = embedder.encode(chunks, show_progress_bar=True)\n",
    "    print(f\"✅ Generated {len(embeddings)} embeddings\")\n",
    "    return embeddings.tolist()\n",
    "\n",
    "print(\"✅ Document processing functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Process Your PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Processing: 1706.03762v7.pdf\n",
      "==================================================\n",
      "📄 Processing 15 pages...\n",
      "✅ Extracted 39487 characters from PDF\n",
      "✅ Created 88 chunks\n",
      "🔄 Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f228980a014e2b862bf2af538b4907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 88 embeddings\n",
      "\n",
      "💾 Storing in vector database...\n",
      "🗑️  Cleared 88 existing documents from database\n",
      "✅ Stored 88 chunks in ChromaDB\n",
      "\n",
      "📊 Summary:\n",
      "  - Total characters: 39,487\n",
      "  - Number of chunks: 88\n",
      "  - Avg chunk size: 448 chars\n",
      "\n",
      "✅ PDF processed successfully! Ready for questions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def process_pdf(pdf_path: str, clear_existing: bool=False):\n",
    "    \"\"\"Complete PDF processing pipeline\"\"\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"❌ File not found: {pdf_path}\")\n",
    "        print(\"Please update PDF_PATH with your file name\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\n📚 Processing: {pdf_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Extract text\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        return False\n",
    "    \n",
    "    # Create chunks\n",
    "    chunks = create_chunks(text)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = embed_chunks(chunks)\n",
    "    \n",
    "    # Store in ChromaDB\n",
    "    print(\"\\n💾 Storing in vector database...\")\n",
    "    \n",
    "    # Clear existing documents (optional)\n",
    "    if clear_existing:\n",
    "        try:\n",
    "            # Get all document IDs first, then delete them\n",
    "            existing_docs = collection.get()\n",
    "            if existing_docs['ids']:\n",
    "                collection.delete(ids=existing_docs['ids'])\n",
    "                print(f\"🗑️  Cleared {len(existing_docs['ids'])} existing documents from database\")\n",
    "            else:\n",
    "                print(\"🗑️  Database was already empty\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Warning: Could not clear existing documents: {e}\")\n",
    "            \n",
    "    # Add documents with metadata\n",
    "    ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
    "    metadatas = [{\"source\": pdf_path, \"chunk_id\": i} for i in range(len(chunks))]\n",
    "    \n",
    "    collection.add(\n",
    "        embeddings=embeddings,\n",
    "        documents=chunks,\n",
    "        ids=ids,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Stored {len(chunks)} chunks in ChromaDB\")\n",
    "    print(f\"\\n📊 Summary:\")\n",
    "    print(f\"  - Total characters: {len(text):,}\")\n",
    "    print(f\"  - Number of chunks: {len(chunks)}\")\n",
    "    print(f\"  - Avg chunk size: {len(text)//len(chunks)} chars\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Process your PDF\n",
    "if process_pdf(PDF_PATH, clear_existing=True):\n",
    "    print(\"\\n✅ PDF processed successfully! Ready for questions.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Please update PDF_PATH and run this cell again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Query functions ready\n"
     ]
    }
   ],
   "source": [
    "def search_similar_chunks(query: str, top_k: int = TOP_K) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Search for most relevant chunks in vector database\"\"\"\n",
    "    \n",
    "    # Generate embedding for query\n",
    "    query_embedding = embedder.encode([query])[0].tolist()\n",
    "    \n",
    "    # Search in ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Extract chunks and distances\n",
    "    chunks = results['documents'][0] if results['documents'] else []\n",
    "    distances = results['distances'][0] if results['distances'] else []\n",
    "    \n",
    "    return list(zip(chunks, distances))\n",
    "\n",
    "def query_lm_studio(prompt: str, temperature: float = 0.7) -> str:\n",
    "    \"\"\"Send query to LM Studio\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"local-model\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context. Be concise and accurate. USE ONLY THE PROVIDE CONTEXT TO ANSWER THE QUESTION.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=3500,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        return \"Error: LM Studio request timed out\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def ask_question(question: str, show_context: bool = False) -> str:\n",
    "    \"\"\"Complete RAG pipeline: retrieve context and generate answer\"\"\"\n",
    "    \n",
    "    print(f\"\\n🔍 Question: {question}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Search for relevant chunks\n",
    "    print(\"Searching for relevant context...\")\n",
    "    relevant_chunks = search_similar_chunks(question)\n",
    "    \n",
    "    if not relevant_chunks:\n",
    "        return \"No relevant information found in the document.\"\n",
    "    \n",
    "    # Prepare context\n",
    "    context = \"\\n\\n\".join([chunk for chunk, _ in relevant_chunks])\n",
    "    \n",
    "    if show_context:\n",
    "        print(\"\\n📄 Retrieved Context:\")\n",
    "        for i, (chunk, distance) in enumerate(relevant_chunks, 1):\n",
    "            print(f\"\\nChunk {i} (similarity: {1-distance:.2f}):\")\n",
    "            print(f\"{chunk}\" )\n",
    "    \n",
    "    # Create prompt with context\n",
    "    prompt = f\"\"\"Based ONLY on the following context, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Get answer from LM Studio\n",
    "    print(\"\\n🤖 Generating answer...\")\n",
    "    answer = query_lm_studio(prompt)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "print(\"✅ Query functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Q&A Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Question: What is 'Attention' - explain for a business user?\n",
      "==================================================\n",
      "Searching for relevant context...\n",
      "\n",
      "📄 Retrieved Context:\n",
      "\n",
      "Chunk 1 (similarity: 0.48):\n",
      "benefit, self-attention could yield more interpretable models. We inspect attention distributions\n",
      "from our models and present and discuss examples in the appendix. Not only do individual attention\n",
      "heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\n",
      "and semantic structure of the sentences.\n",
      "5 Training\n",
      "This section describes the training regime for our models.\n",
      "5.1 Training Data and Batching\n",
      "We trained on the standard WMT 2014 English-German data\n",
      "\n",
      "Chunk 2 (similarity: 0.45):\n",
      "ned with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position ican depend only on the known outputs at positions less than i.\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "Scaled Dot-Product Attention\n",
      " Multi-Head Attention\n",
      "Figure 2: (left) Scaled Dot-Product Attention. (right) Mu\n",
      "\n",
      "Chunk 3 (similarity: 0.44):\n",
      "d\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the\n",
      "encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\n",
      "the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\n",
      "the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
      "\n",
      "Chunk 4 (similarity: 0.44):\n",
      "educed to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abst\n",
      "\n",
      "Chunk 5 (similarity: 0.41):\n",
      "single-head attention with full dimensionality.\n",
      "3.2.3 Applications of Attention in our Model\n",
      "The Transformer uses multi-head attention in three different ways:\n",
      "•In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\n",
      "and the memory keys and values come from the output of the encoder. This allows every\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence mod\n",
      "\n",
      "🤖 Generating answer...\n",
      "\n",
      "💬 Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Attention** is a way for the model to “look back” at different parts of a sentence (or any sequence) when it is trying to understand or generate text. Think of it as a smart spotlight that highlights the most relevant words for each word being processed.\n",
       "\n",
       "- **How it works**: For every word, the model creates a small “query” vector. It then compares this query to all other words (the “keys”) and assigns a weight to each comparison. These weights decide how much each word should influence the current word’s representation.\n",
       "- **Why it matters**: By focusing on the most important words, the model can capture long‑range relationships (e.g., a verb and its distant object) without needing to read the entire sentence multiple times. This makes the model more accurate and, because each attention “head” can learn a different pattern (syntax, semantics, etc.), it also becomes easier to interpret what the model is doing.\n",
       "\n",
       "In business terms, attention lets a language system understand context more precisely—like spotting the key factors in a customer review or linking a product mention to its description—leading to better translations, summaries, or insights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with a sample question\n",
    "sample_question = \"What is 'Attention' - explain for a business user?\"  # <-- Change this to test\n",
    "\n",
    "answer = ask_question(sample_question, show_context=True)\n",
    "print(\"\\n💬 Answer:\")\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Vector Database Statistics:\n",
      "  - Total chunks: 88\n",
      "  - Embedding dimensions: 384\n",
      "  - Storage location: ./chroma_db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_collection_stats():\n",
    "    \"\"\"Display statistics about the vector database\"\"\"\n",
    "    count = collection.count()\n",
    "    print(f\"📊 Vector Database Statistics:\")\n",
    "    print(f\"  - Total chunks: {count}\")\n",
    "    print(f\"  - Embedding dimensions: {len(embedder.encode(['test'])[0])}\")\n",
    "    print(f\"  - Storage location: ./chroma_db\")\n",
    "    return count\n",
    "\n",
    "def clear_database():\n",
    "    \"\"\"Clear all documents from the database\"\"\"\n",
    "    collection.delete(where={})\n",
    "    print(\"🗑️ Database cleared\")\n",
    "\n",
    "def process_multiple_pdfs(pdf_paths: List[str]):\n",
    "    \"\"\"Process multiple PDF files\"\"\"\n",
    "    for path in pdf_paths:\n",
    "        process_pdf(path)\n",
    "        print()\n",
    "\n",
    "# Display current stats\n",
    "get_collection_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
